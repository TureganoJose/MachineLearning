#https://arxiv.org/pdf/1905.01697.pdf


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Flatten, Conv2D, DepthwiseConv2D, MaxPool2D, Input
from tensorflow.keras import regularizers
from tensorflow.keras import Model

def plot_axis(ax, x, y, title):
    ax.plot(x, y)
    ax.set_title(title)
    ax.xaxis.set_visible(False)
    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])
    ax.set_xlim([min(x), max(x)])
    ax.grid(True)

def cnn_layers(model_input):
    # Dilation layer 1
    x = keras.layers.Conv2D(32, (3, 10), strides=(1, 1), padding='same', data_format='channels_last', dilation_rate=(1, 2),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(model_input)
    x = keras.layers.Conv2D(32, (1, 2), strides=(1, 2), padding='valid', data_format=None, dilation_rate=(1, 1),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(x)
    # Dilation layer 2
    x = keras.layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', data_format=None, dilation_rate=(1, 2),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(x)
    x = keras.layers.Conv2D(32, (1, 2), strides=(1, 2), padding='same', data_format=None, dilation_rate=(1, 1),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(x)
    # Dilation layer 3
    x = keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', data_format=None, dilation_rate=(1, 1),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(x)
    x = keras.layers.Conv2D(64, (1, 2), strides=(1, 2), padding='same', data_format=None, dilation_rate=(1, 1),
                            activation='relu', use_bias=True, kernel_initializer='glorot_uniform',
                            bias_initializer='zeros', kernel_regularizer=regularizers.l2(1e-5))(x)
    # Fully connected
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    prediction = Dense(6, activation='softmax')(x)
    return prediction

# Check that it detects my GPU
#tf.test.is_built_with_cuda()

#tf.config.list_physical_devices('GPU')

#tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)

# Pre-processing data
#segments = np.load('segments.npy')
#labels = np.load('labels.npy')
#
#reshaped_segments = segments.reshape(len(segments), 3, 90, 1)
##mod_segment = segments.swapaxes(2, 0)
##reshaped_segments = segments.reshape(len(mod_segment), 3, 90, 1)
#
#train_test_split = np.random.rand(len(reshaped_segments)) < 0.70
#train_x = reshaped_segments[train_test_split]
#train_y = labels[train_test_split]
#test_x = reshaped_segments[~train_test_split]
#test_y = labels[~train_test_split]



train_x = np.load('TRAIN_feat_sp_v2_200.npy')
train_y = np.load('TRAIN_label_sp_v2_200.npy')

train_x = train_x.transpose(0, 2, 1)

test_x = np.load('TEST_feat_sp_v2_200.npy')
test_y = np.load('TEST_label_sp_v2_200.npy')

test_x = test_x.transpose(0, 2, 1)

train_x = np.expand_dims(train_x, axis=3)
test_x = np.expand_dims(test_x, axis=3)

# Creating dataset https://keras.io/examples/mnist_dataset_api/

dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))
#dataset = dataset.repeat()
#dataset = dataset.shuffle(buffer_size)
Train_Batch_size = train_x.shape
batch_size = int(Train_Batch_size[0]/100)
dataset = dataset.batch(batch_size, drop_remainder=True)
dataset = dataset.prefetch(1)

dataset_val = tf.data.Dataset.from_tensor_slices((test_x, test_y))
dataset_val = dataset_val.batch(batch_size, drop_remainder=True)
dataset_val = dataset_val.prefetch(1)


#iterator = iter(dataset)

input_height = 1
input_width = 90
num_labels = 6
num_channels = 3

kernel_size = 60
depth = 60
num_hidden = 1000

learning_rate = 0.0001
training_epochs = 20

# Float64 by default in layers
tf.keras.backend.set_floatx('float64')

model_input = Input(shape=(200, 3, 1))
model_output = cnn_layers(model_input)
train_model = Model(inputs=model_input, outputs=model_output)
#train_model = keras.models.Model(inputs=model_input, outputs=model_output)

train_model.compile(loss=keras.losses.categorical_crossentropy,
                    optimizer=keras.optimizers.Nadam(lr=learning_rate),
                    metrics=['accuracy'])

train_model.summary()

history = train_model.fit(dataset,
          epochs=training_epochs,
          verbose=1,
          validation_data = dataset_val)

score = train_model.evaluate(test_x, test_y, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

